{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from matplotlib import pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format = 'retina'\n",
    "\n",
    "# Set sensible defaults\n",
    "sns.set()\n",
    "sns.set_style(\"ticks\")\n",
    "sns.set_context('talk')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import openai\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "openai.api_key = os.environ[\"OPENAI_API_KEY\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((2100, 4), (2100, 1536))"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load data at startup\n",
    "df_metadata = pd.read_csv('metadata.csv')\n",
    "with open('embeddings.pkl', 'rb') as f:\n",
    "    embeddings_array = pickle.load(f)\n",
    "\n",
    "df_metadata.shape, embeddings_array.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_embeddings(text):\n",
    "    response = openai.Embedding.create(\n",
    "        model=\"text-embedding-ada-002\",\n",
    "        input=text,\n",
    "    )\n",
    "    return response['data'][0]['embedding']\n",
    "\n",
    "\n",
    "def search_knowledgebase(query, min_score=0.75):\n",
    "    # Get the embedding of the query\n",
    "    query_embedding = get_embeddings(query)\n",
    "    query_embedding = np.array(query_embedding).reshape(1, -1)\n",
    "\n",
    "    # Calculate cosine similarities\n",
    "    similarities = cosine_similarity(query_embedding, embeddings_array)\n",
    "    similarities = similarities.flatten()\n",
    "\n",
    "    # Create a DataFrame for easy manipulation\n",
    "    df = df_metadata.copy()\n",
    "    df['similarity'] = similarities\n",
    "\n",
    "    # Sort by similarity\n",
    "    df_sorted = df.sort_values(by='similarity', ascending=False)\n",
    "\n",
    "    # Get the ranked list of titles and descriptions\n",
    "    results = df_sorted[['title', 'url', 'description', 'similarity']]\n",
    "    results = results[results['similarity'] >= min_score]\n",
    "\n",
    "    return results\n",
    "\n",
    "def search(text: str):\n",
    "    # Perform search\n",
    "    results = search_knowledgebase(text)\n",
    "\n",
    "    # Convert top 5 results to desired format\n",
    "    top_results = results.head(5)\n",
    "    top_results_list = top_results.to_dict('records')\n",
    "\n",
    "    # Prepare response\n",
    "    response = {'results': top_results_list}\n",
    "    return response\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'results': [{'title': 'LLM-Reading-List',\n",
       "   'url': 'https://github.com/evanmiller/LLM-Reading-List',\n",
       "   'description': \"REPO: LLM-Reading-List [2023-07-26T15:16:28Z, stars: 254] | LLM papers I'm reading, mostly on inference and model compression\",\n",
       "   'similarity': 0.7985937347757681},\n",
       "  {'title': 'Natural Language Processing in Electronic Health Records in Relation to\\n  Healthcare Decision-making: A Systematic Review',\n",
       "   'url': 'http://arxiv.org/abs/2306.12834v1',\n",
       "   'description': 'PAPER: Natural Language Processing in Electronic Health Records in Relation to\\n  Healthcare Decision-making: A Systematic Review [2023-06-22T12:10:41Z] |   Background: Natural Language Processing (NLP) is widely used to extract\\nclinical insights from Electronic Health Records (EHRs). However, the lack of\\nannotated data, automated tools, and other challenges hinder the full\\nutilisation of NLP for EHRs. Various Machine Learning (ML), Deep Learning (DL)\\nand NLP techniques are studied and compared to understand the limitations and\\nopportunities in this space comprehensively.\\n  Methodology: After screening 261 articles from 11 databases, we included 127\\npapers for full-text review covering seven categories of articles: 1) medical\\nnote classification, 2) clinical entity recognition, 3) text summarisation, 4)\\ndeep learning (DL) and transfer learning architecture, 5) information\\nextraction, 6) Medical language translation and 7) other NLP applications. This\\nstudy follows the Preferred Reporting Items for Systematic Reviews and\\nMeta-Analyses (PRISMA) guidelines.\\n  Result and Discussion: EHR was the most commonly used data type among the\\nselected articles, and the datasets were primarily unstructured. Various ML and\\nDL methods were used, with prediction or classification being the most common\\napplication of ML or DL. The most common use cases were: the International\\nClassification of Diseases, Ninth Revision (ICD-9) classification, clinical\\nnote analysis, and named entity recognition (NER) for clinical descriptions and\\nresearch on psychiatric disorders.\\n  Conclusion: We find that the adopted ML models were not adequately assessed.\\nIn addition, the data imbalance problem is quite important, yet we must find\\ntechniques to address this underlining problem. Future studies should address\\nkey limitations in studies, primarily identifying Lupus Nephritis, Suicide\\nAttempts, perinatal self-harmed and ICD-9 classification.\\n',\n",
       "   'similarity': 0.7884625472915067},\n",
       "  {'title': 'Llama-2-Open-Source-LLM-CPU-Inference',\n",
       "   'url': 'https://github.com/kennethleungty/Llama-2-Open-Source-LLM-CPU-Inference',\n",
       "   'description': 'REPO: Llama-2-Open-Source-LLM-CPU-Inference [2023-07-06T05:42:43Z, stars: 545] | Running Llama 2 and other Open-Source LLMs on CPU Inference Locally for Document\\xa0Q&A',\n",
       "   'similarity': 0.7804438907334169},\n",
       "  {'title': 'LLM-eval-survey',\n",
       "   'url': 'https://github.com/MLGroupJLU/LLM-eval-survey',\n",
       "   'description': 'REPO: LLM-eval-survey [2023-07-02T03:23:20Z, stars: 592] | The official GitHub page for the survey paper \"A Survey on Evaluation of Large Language Models\".',\n",
       "   'similarity': 0.7779170627964639},\n",
       "  {'title': 'InternLM',\n",
       "   'url': 'https://github.com/InternLM/InternLM',\n",
       "   'description': 'REPO: InternLM [2023-07-06T04:52:06Z, stars: 2278] | InternLM has open-sourced a 7 billion parameter base model, a chat model tailored for practical scenarios and the training system.',\n",
       "   'similarity': 0.7748309510505613}]}"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "search('I am an angel investor interested in understanding LLMs so I can perform due diligence on pre-seed startups. angel investor, due diligence, pre-seed startups, LLMs, understanding, machine learning, natural language processing, deep learning, neural networks, artificial intelligence, data analysis, predictive modeling, investment strategy, risk assessment, startup evaluation, decision making, venture capital, investment opportunities, technology trends, market research, industry analysis, startup ecosystem, investment portfolio, startup valuation, early-stage companies, investment thesis, startup funding, angel investing, startup growth, startup success, founder evaluation, business model, competitive advantage, market potential, scalability, product-market fit, revenue model, customer acquisition, traction, team assessment, leadership, market disruption, innovation, industry disruption, regulatory landscape, intellectual property, exit strategy, startup ecosystem, mentorship, networking, startup community, startup ecosystem, startup incubator, startup accelerator')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "CONSTANTS = {\n",
    "  \"vibes\": {\n",
    "    \"identities\": [\"an Investor\", \"a Tech Founder\"],\n",
    "    \"interests\": [\"Generative AI\", \"AI Agents\"],\n",
    "    \"goals\": [\n",
    "      \"know what insiders are talking about\",\n",
    "      \"assess early-stage tech startups\",\n",
    "      \"build better products\"\n",
    "    ]\n",
    "  },\n",
    "  \"prompts\": {\n",
    "    \"vibeparse\": {\n",
    "      \"max_tokens\": 200,\n",
    "      \"model\": \"gpt-3.5-turbo\",\n",
    "      \"temperature\": 0.5,\n",
    "      \"messages\": [\n",
    "        {\n",
    "          \"role\": \"system\",\n",
    "          \"content\": \"You are a helpful assistant who helps users find articles, github repos, and arXiv papers they might be interested in. The user tells you about themself, their interests, and their goals. You return a comma-separated list of 50 key terms that are relevant to the user and their interests.\"\n",
    "        }\n",
    "      ]\n",
    "    },\n",
    "    \"justify\": {\n",
    "      \"max_tokens\": 300,\n",
    "      \"model\": \"gpt-3.5-turbo-0613\",\n",
    "      \"temperature\": 0.2,\n",
    "      \"functions\": [\n",
    "        {\n",
    "          \"name\": \"augment_resource\",\n",
    "          \"description\": \"Tailor a resource to the user's identity, interests, and goals.\",\n",
    "          \"parameters\": {\n",
    "            \"type\": \"object\",\n",
    "            \"properties\": {\n",
    "              \"short_summary\": {\n",
    "                \"type\": \"string\",\n",
    "                \"description\": \"A one-sentence summary of the resource, tailored to the user's identity, interests, and goals.\"\n",
    "              },\n",
    "              \"justification\": {\n",
    "                \"type\": \"string\",\n",
    "                \"description\": \"A two-sentence justification for why the resource is relevant to the user, based on their goals.\"\n",
    "              }\n",
    "            },\n",
    "            \"required\": [\"short_summary\", \"justification\"]\n",
    "          }\n",
    "        }\n",
    "      ],\n",
    "      \"function_call\": { \"name\": \"augment_resource\" },\n",
    "      \"messages\": [\n",
    "        {\n",
    "          \"role\": \"system\",\n",
    "          \"content\": \"You are a helpful assistant who helps the user make sense of articles, github repos, and arXiv papers they might be interested in given their identity, interests, and goals. Only use the functions you have been provided with.\"\n",
    "        }\n",
    "      ]\n",
    "    },\n",
    "  }\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I am an angel investor interested in understanding LLMs so I can perform due diligence on pre-seed startups.\n",
      "angel investor, due diligence, pre-seed startups, understanding LLMs, machine learning, natural language processing, deep learning, language models, artificial intelligence, investment, startups, venture capital, risk assessment, decision making, investment analysis, startup evaluation, predictive modeling, data analysis, investment strategy, investment portfolio, investment opportunities, investment trends, startup ecosystem, technology startups, early-stage startups, startup funding, investment thesis, investment criteria, startup valuation, market analysis, competitive analysis, industry research, investment landscape, startup growth, startup success, startup failure, investment risks, investment returns, startup scalability, market potential, market size, market demand, customer acquisition, revenue model, business model, competitive advantage, intellectual property, team assessment, founder evaluation, market fit, product-market fit, market research, industry trends\n",
      "[{'title': 'LLM-Reading-List', 'url': 'https://github.com/evanmiller/LLM-Reading-List', 'description': \"REPO: LLM-Reading-List [2023-07-26T15:16:28Z, stars: 254] | LLM papers I'm reading, mostly on inference and model compression\", 'similarity': 0.8017758956475782}, {'title': 'LLM-eval-survey', 'url': 'https://github.com/MLGroupJLU/LLM-eval-survey', 'description': 'REPO: LLM-eval-survey [2023-07-02T03:23:20Z, stars: 592] | The official GitHub page for the survey paper \"A Survey on Evaluation of Large Language Models\".', 'similarity': 0.7841601891782991}, {'title': 'Natural Language Processing in Electronic Health Records in Relation to\\n  Healthcare Decision-making: A Systematic Review', 'url': 'http://arxiv.org/abs/2306.12834v1', 'description': 'PAPER: Natural Language Processing in Electronic Health Records in Relation to\\n  Healthcare Decision-making: A Systematic Review [2023-06-22T12:10:41Z] |   Background: Natural Language Processing (NLP) is widely used to extract\\nclinical insights from Electronic Health Records (EHRs). However, the lack of\\nannotated data, automated tools, and other challenges hinder the full\\nutilisation of NLP for EHRs. Various Machine Learning (ML), Deep Learning (DL)\\nand NLP techniques are studied and compared to understand the limitations and\\nopportunities in this space comprehensively.\\n  Methodology: After screening 261 articles from 11 databases, we included 127\\npapers for full-text review covering seven categories of articles: 1) medical\\nnote classification, 2) clinical entity recognition, 3) text summarisation, 4)\\ndeep learning (DL) and transfer learning architecture, 5) information\\nextraction, 6) Medical language translation and 7) other NLP applications. This\\nstudy follows the Preferred Reporting Items for Systematic Reviews and\\nMeta-Analyses (PRISMA) guidelines.\\n  Result and Discussion: EHR was the most commonly used data type among the\\nselected articles, and the datasets were primarily unstructured. Various ML and\\nDL methods were used, with prediction or classification being the most common\\napplication of ML or DL. The most common use cases were: the International\\nClassification of Diseases, Ninth Revision (ICD-9) classification, clinical\\nnote analysis, and named entity recognition (NER) for clinical descriptions and\\nresearch on psychiatric disorders.\\n  Conclusion: We find that the adopted ML models were not adequately assessed.\\nIn addition, the data imbalance problem is quite important, yet we must find\\ntechniques to address this underlining problem. Future studies should address\\nkey limitations in studies, primarily identifying Lupus Nephritis, Suicide\\nAttempts, perinatal self-harmed and ICD-9 classification.\\n', 'similarity': 0.7839115755485906}, {'title': 'Llama-2-Open-Source-LLM-CPU-Inference', 'url': 'https://github.com/kennethleungty/Llama-2-Open-Source-LLM-CPU-Inference', 'description': 'REPO: Llama-2-Open-Source-LLM-CPU-Inference [2023-07-06T05:42:43Z, stars: 545] | Running Llama 2 and other Open-Source LLMs on CPU Inference Locally for Document\\xa0Q&A', 'similarity': 0.7815470625461748}, {'title': 'InternLM', 'url': 'https://github.com/InternLM/InternLM', 'description': 'REPO: InternLM [2023-07-06T04:52:06Z, stars: 2278] | InternLM has open-sourced a 7 billion parameter base model, a chat model tailored for practical scenarios and the training system.', 'similarity': 0.7781925182392334}]\n",
      "5\n"
     ]
    }
   ],
   "source": [
    "from copy import deepcopy as copy\n",
    "# User's input to frontend\n",
    "raw_vibe = \"I am an angel investor interested in understanding LLMs so I can perform due diligence on pre-seed startups.\"\n",
    "print(raw_vibe)\n",
    "\n",
    "# Extend the user's \"vibe\" with GPT\n",
    "params = copy(CONSTANTS['prompts']['vibeparse'])\n",
    "params['messages'].append(\n",
    "    {\"role\": \"user\", \"content\": raw_vibe}\n",
    ")\n",
    "vibe_ext = openai.ChatCompletion.create(\n",
    "    **params,\n",
    ").choices[0].message.content\n",
    "print(vibe_ext)\n",
    "\n",
    "# Perform embedding search\n",
    "results = search(f\"{raw_vibe}, {vibe_ext}\")['results']\n",
    "print(results)\n",
    "print(len(results))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LLM-Reading-List\n",
      "https://github.com/evanmiller/LLM-Reading-List\n",
      "LLM-Reading-List is a curated list of papers on LLMs, focusing on inference and model compression.\n",
      "This resource is relevant to you as an angel investor interested in understanding LLMs for due diligence on pre-seed startups.\n",
      "\n",
      "\n",
      "LLM-eval-survey\n",
      "https://github.com/MLGroupJLU/LLM-eval-survey\n",
      "A Survey on Evaluation of Large Language Models\n",
      "This survey paper provides an overview of the evaluation methods and challenges for large language models, which can help you assess the quality and capabilities of pre-seed startups utilizing LLMs.\n",
      "\n",
      "\n",
      "Natural Language Processing in Electronic Health Records in Relation to\n",
      "  Healthcare Decision-making: A Systematic Review\n",
      "http://arxiv.org/abs/2306.12834v1\n",
      "Natural Language Processing in Electronic Health Records in Relation to Healthcare Decision-making: A Systematic Review\n",
      "This paper provides a systematic review of the use of Natural Language Processing (NLP) in Electronic Health Records (EHRs) for healthcare decision-making. As an angel investor interested in understanding LLMs, this resource is relevant because it explores the limitations and opportunities of NLP techniques in the healthcare domain, which can be valuable for performing due diligence on pre-seed startups in the healthcare industry.\n",
      "\n",
      "\n",
      "Llama-2-Open-Source-LLM-CPU-Inference\n",
      "https://github.com/kennethleungty/Llama-2-Open-Source-LLM-CPU-Inference\n",
      "Llama-2-Open-Source-LLM-CPU-Inference is a GitHub repository that allows you to run Llama 2 and other open-source LLMs on CPU inference locally for document Q&A.\n",
      "This resource is relevant to you as an angel investor interested in understanding LLMs for due diligence on pre-seed startups because it provides a practical implementation of LLMs for document Q&A, which can be useful for analyzing startup documents and extracting relevant information.\n",
      "\n",
      "\n",
      "InternLM\n",
      "https://github.com/InternLM/InternLM\n",
      "InternLM is a GitHub repository that provides a 7 billion parameter base model for language models.\n",
      "This repository is relevant to you as an angel investor because it can help you understand the capabilities and potential of large language models, which can be valuable for due diligence on pre-seed startups.\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "# Loop through results and justify each one\n",
    "for result in results:\n",
    "    params = copy(CONSTANTS['prompts']['justify'])\n",
    "    params['messages'].extend([\n",
    "        {\"role\": \"user\", \"content\": raw_vibe},\n",
    "        {\"role\": \"user\", \"content\": str(result)},\n",
    "    ])\n",
    "    justification = openai.ChatCompletion.create(\n",
    "        **params,\n",
    "    ).choices[0]['message']['function_call']['arguments']\n",
    "    justification = json.loads(justification)\n",
    "    summary = justification['short_summary']\n",
    "    reason = justification['justification']\n",
    "    print(f\"{result['title']}\\n{result['url']}\\n{summary}\\n{reason}\\n\\n\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
